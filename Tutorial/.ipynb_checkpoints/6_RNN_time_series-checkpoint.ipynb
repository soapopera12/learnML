{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9edf92-5ee1-4c69-8c6b-ad10f1b9b00e",
   "metadata": {},
   "source": [
    "## Processing Sequences Using RNNs and CNNs\n",
    "\n",
    "### Recurrent Neural Network\n",
    "\n",
    "recognizes patterns in sequences of data, such as time series, speech, text, and video\n",
    "\n",
    "**Recurrent layer**\n",
    "\n",
    "At each time step t (also called a frame), the recurrent neuron receives the inputs $x_t$ as well as its own output from the previous time step, $\\hat{y}_{t-1}$.\n",
    "\n",
    "For a layer of recurrent neurons \n",
    "\n",
    "$\\hat{y}_t = f(W_{x}.x_t + W_{\\hat{y}}.\\hat{y}_{t-1}+b)$\n",
    "\n",
    "$W_x$ is the weight vector for inputs\n",
    "\n",
    "$W_{\\hat{y}}$ is the weight vector for output of the previous step t-1\n",
    "\n",
    "**Input and output sequences**\n",
    "\n",
    "sequence-to-sequence network: a sequence of inputs produces a sequence of outputs → daily power consumption\n",
    "\n",
    "sequence-to-vector network: a sequence of inputs ignoring all outputs except for the last one → movie review\n",
    "\n",
    " vector-to-sequence network: the same input vector over and over again at each time step and let it output a sequence → image captioning\n",
    "\n",
    "encoder (sequence-to-vector) → followed by → decoder (vector-to-sequence) → translation from one language to another\n",
    "\n",
    "### Training RNNs\n",
    "\n",
    "seasonality\n",
    "\n",
    "trend\n",
    "\n",
    "differencing\n",
    "\n",
    "moving averages\n",
    "\n",
    "### ARMA model family\n",
    "\n",
    "It consists of two main types of models: the AR (AutoRegressive) model and the MA (Moving Average) model.\n",
    "\n",
    "1.  **AutoRegressive (AR) Model**\n",
    "    \n",
    "    The AutoRegressive model specifies that the output variable depends linearly on its own previous values.\n",
    "    \n",
    "    $X_t = c + \\phi_1 X_{t-1}+\\phi_2 X_{t-2}+\\cdot\\cdot\\cdot+\\phi_p X_{t-p} + \\epsilon_t$\n",
    "    \n",
    "    - $X_t$ is the time series at time t.\n",
    "    - c is a constant.\n",
    "    - ϕ1,ϕ2,…,ϕp are the parameters of the model.\n",
    "    - $\\epsilon_t$ is white noise error term at time t, typically assumed to be normally distributed with mean 0 and variance $\\sigma^2$.\n",
    "2. **Moving Average (MA) Model**\n",
    "    \n",
    "    The Moving Average model specifies that the output variable depends linearly on the current and past values of a stochastic (white noise) term.\n",
    "    \n",
    "    $X_t = c + \\epsilon_t + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdot \\cdot \\cdot+ \\theta_q\\epsilon_{t-q}$\n",
    "    \n",
    "    - $X_t$ is the time series at time t.\n",
    "    - c is a constant.\n",
    "    - $\\epsilon_t, \\epsilon_{t-1},\\cdot \\cdot\\cdot,\\epsilon_{t-q}$ are white noise error terms.\n",
    "    - $\\theta_1, \\theta_2, \\cdot \\cdot\\cdot ,\\theta_1$ are the parameters of the model.\n",
    "\n",
    "Combining the AR and MA models we get\n",
    "\n",
    "$X_t = c + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdot \\cdot \\cdot + \\phi_p X_{t-p} + \\epsilon_t + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdot \\cdot \\cdot+ \\theta_q\\epsilon_{t-q}$\n",
    "\n",
    "- $X_t$ is the time series at time t.\n",
    "- c is a constant.\n",
    "- ϕ1,ϕ2,…,ϕp are the parameters of the AR part of the model.\n",
    "- θ1,θ2,…,θq are the parameters of the MA part of the model.\n",
    "- $\\epsilon_t$ is white noise term.\n",
    "\n",
    "**Differencing + ARMA = ARIMA (Auto Regressive Integrated Moving Average) model**\n",
    "\n",
    "**Seasonality + ARIMA = SARIMA ( Seasonal Auto Regressive Integrated Moving Average) model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843386e8-926a-4417-9948-2a8170286e07",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "special kind of RNN, capable of learning long-term dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c1e85-72b1-48c1-8f8b-31e53f527b14",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"Images/LSTM.png\" alt=\"LSTM\" style=\"width: 500px; height: 300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3658c2-5e4e-4ac1-8a2a-075879bd5c66",
   "metadata": {},
   "source": [
    "Variants of LSTM\n",
    "\n",
    "peephole\n",
    "\n",
    "coupled forget and input gates\n",
    "\n",
    "GRU\n",
    "\n",
    "Excellent blog to understand LSTM :[https://colah.github.io/posts/2015-08-Understanding-LSTMs/]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda118",
   "language": "python",
   "name": "cuda118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
