{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ab5ce0-6291-4153-a202-66aa406efe3c",
   "metadata": {},
   "source": [
    "## Deep Computer Vision Using Convolutional Neural Networks\n",
    "\n",
    "### **Step 1: Convolutional Layers**\n",
    "\n",
    "Purpose: To extract features from the input image.\n",
    "\n",
    "1. Filters/Kernels\n",
    "    \n",
    "    **Filters/Kernels**\n",
    "    \n",
    "     Small matrices (e.g., 3x3 or 5x5) that slide over the input image, computing dot products between the filter and patches of the input. This operation is called a convolution. \n",
    "    \n",
    "    i/p → layer (filter/s) → o/p (feature map)\n",
    "    \n",
    "    The filters are not to be set manually but training the CNN will automatically learn the most useful filters for it’s task\n",
    "    \n",
    "2. Feature Maps\n",
    "    \n",
    "    The result of applying a filter to an input, highlighting specific features such as edges, textures, or patterns.\n",
    "    \n",
    "    Each convolutional layer outputs one feature map per filter.\n",
    "    \n",
    "\n",
    "Remember padding = “valid” is not setting zero-padding so the output feature map will reduce in size \n",
    "\n",
    "padding = “same” is adding zeros around the input image to ensure the output feature map has the same size as the input. Padding helps retain spatial dimensions after convolution.\n",
    "\n",
    "The step size by which the filter moves over the input. A stride of 1 means the filter moves one pixel at a time.\n",
    "\n",
    "### Step 2: Activation functions\n",
    "\n",
    "simply Relu can you used to introduce non-linearity.\n",
    "\n",
    "Why should i introduce non-linearity?\n",
    "\n",
    "Linear models (without non-linear activation functions) can only learn linear relationships between inputs and outputs. This means they can only model straight-line relationships in the data. However, most real-world data exhibit complex, non-linear relationships. Non-linear activation functions allow the network to learn and approximate these complex patterns and functions.\n",
    "\n",
    "### Step 3: Pooling layers\n",
    "\n",
    "Reduces the spatial dimensions of the feature map, thereby reducing the number of parameters and computational load.\n",
    "\n",
    "Max Pooling (selects the maximum value) and Average Pooling (computes the average value) → [i](http://i.ps)/ps not fulfilling the criteria are dropped\n",
    "\n",
    "### Step 4: Fully **Connected Layer**\n",
    "\n",
    "The output from the convolutional and pooling layers is flattened into a 1D vector and fed into one or more fully connected layers these are normal neural network layers.\n",
    "\n",
    "**Data augmentation**\n",
    "\n",
    "Data augmentation artificially increases the size of the training set by slightly shift, rotate, and resize every picture which in turn adds the resulting pictures to the training data reducing overfitting, making this a regularization technique\n",
    "\n",
    "### Famous CNN architectures\n",
    "\n",
    "1. **LeNET-5**\n",
    "2. AlexNet\n",
    "3. GoogleNet\n",
    "4. VGGNet\n",
    "5. ResNet\n",
    "6. Xception\n",
    "7. SENet\n",
    "\n",
    "---\n",
    "\n",
    "### Classification and Localization\n",
    "\n",
    "This can be expressed as a regression task, the aim is to predict a bounding box around the image.\n",
    "\n",
    "4 numbers are to be predicted → horizontal and vertical coordinates of the object’s center, as well as its height and width.\n",
    "\n",
    "So to the same CNN model that were prepared above we just need to add a second dense output layer with four units typically on top of the global average pooling layer.\n",
    "\n",
    "Intersection over Union (IoU) can be used instead of MSE as metric for evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Object detection\n",
    "\n",
    "A sliding CNN is used to detect multiple objects\n",
    "\n",
    "But this detects the same object multiple times so the unnecessary boxes can be eliminated using non-max suppression.\n",
    "\n",
    "1. Fully Convolutional Network (FCN).\n",
    "2. You Only Look Once (YOLO).\n",
    "\n",
    "---\n",
    "\n",
    "### Object tracking\n",
    "\n",
    "1. DeepSORT\n",
    "\n",
    "---\n",
    "\n",
    "### Semantic segmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda118",
   "language": "python",
   "name": "cuda118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
